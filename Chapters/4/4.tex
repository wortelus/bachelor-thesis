\section{Řešení pomocí sítě U-Net++}
\label{sec:Chapter44}
Síť U-Net++ se odvíjí od architektury U-Net v předchozí kapitole \ref{sec:Chapter43}, rozšiřující její možnosti a sémanticky propojující části enkodéru a dekodéru svými skokovými bloky \cite{unetpp}. Jako v předchozí kapitole, rozhodujeme se pro volbu 4 bloků enkodéru a dekodéru, počínající od počtu 32 filtrů po 256 filtrů v poslední bloku enkodéru a prvním bloku dekodéru, s krkem obsahující 512 filtrů. Implementační detaily týkající se návrhu bloků 3 hlavních částí U-Net je obdobné s obecným návrhem v kapitole \ref{sec:Chapter42}. Tyto návrhy bloků jsou obdobně použity i pro hluboké skokové bloky, přidány v rámci sítě U-Net++ \cite{unetpp}.

Skokové bloky přidány v této síti jsou přidány mezi vrstvy dekodéru a enkodéru v rámci pokusu vylepšení výsledků původní sítě U-Net. Premise a detaily vylepšení této sítě jsou detailně popsány v kapitole \ref{sec:Chapter23}. Sémantickou vrstvou sítě U-Net++ rozumíme množinu společně relevantních bloků vizuálně reprezentovanou v sekci (b) na obrázku \ref{fig:unetpp}. Skokových bloků bylo přidáno odpovídající množství pro návrh sítě s 4 bloky enkodéru, 4 bloky dekodéru a 1 bloku krku, obdobně jak je na obrázku \ref{fig:unetpp}. Konkrétně se jedná o bloky $X^{0,1}$, $X^{0,2}$, $X^{0,3}$ v první sémantické vrstvě sítě U-Net++, $X^{1,1}$, $X^{1,2}$ ve vrstvě druhé a poté $X^{3,1}$ na vrstvě předposledního (třetího) bloku enkodéru a dekodéru. Skokové bloky přijímají výstup všech předchozích bloků na relevantní sémantické vrstvě propojených (ang. concatenated) na ose filtrů. Bloky dekodéru následují stejné pravidlo, což znamená, že bloky dekodéru přijímají výstup z enkodéru a také ze všech skokových bloků v sémantické vrstvě sítě U-Net++. Přesná formulace propojení na vstupech je vyobrazena v části (b) na obrázku \ref{fig:unetpp}.

Síť je trénována v režimu hluboké supervize na základě výstupu bloků $X^{0,1}$, $X^{0,2}$, $X^{0,3}$, $X^{0,4}$, kde $X^{0,4}$ je výstup poslední vrstvy dekodéru a ostatní 3 jsou výstupy skokových bloků. Samozřejmě ztrátová funkce nepracuje s ReLU výstupy, ale pro každý blok účastnící se hluboké supervize má na svém výstupu aplikovanou $1\times1$ konvoluční vrstvu s aktivační funkcí sigmoid. Při trénování modelu bez hluboké supervize pomocí standardního přístupu zpětné propagace na finální vrstvě se ztrátové funkce účastní pouze finální blok dekodéru $X^{0, 4}$.
\endinput